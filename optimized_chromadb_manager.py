"""
Fixed Optimized ChromaDB Manager - åŸºäºåŸç‰ˆçš„ä¼˜åŒ–
ç›´æ¥å¤åˆ¶è¿™ä¸ªä»£ç æ›¿æ¢ optimized_chromadb_manager.py
"""

import os
import time
import hashlib
from pathlib import Path
from typing import List, Optional, Dict, Any, Tuple
from dotenv import load_dotenv

# Docling imports
from docling.document_converter import DocumentConverter
from docling.datamodel.base_models import InputFormat
from docling.datamodel.pipeline_options import PdfPipelineOptions
from docling.document_converter import PdfFormatOption

# ChromaDB imports
import chromadb
from chromadb.utils import embedding_functions

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

class OptimizedDoclingChromaProcessor:
    """
    ä¼˜åŒ–çš„å¤„ç†å™¨ï¼Œä¿æŒä¸åŸç‰ˆå…¼å®¹çš„æ¥å£
    """
    
    def __init__(self,
                 openai_api_key: str = None,
                 chroma_db_path: str = "./chroma_db",
                 embedding_model: str = "text-embedding-3-small"):  # æ›´å¿«çš„åµŒå…¥æ¨¡å‹
        
        self.openai_api_key = openai_api_key or os.getenv("OPENAI_API_KEY")
        self.chroma_db_path = chroma_db_path
        self.embedding_model = embedding_model
        
        # ä½¿ç”¨åŸç‰ˆçš„åˆå§‹åŒ–æ–¹å¼ï¼Œåªæ˜¯ä¼˜åŒ–å‚æ•°
        self.converter = self._setup_docling_converter()
        self.chroma_client = chromadb.PersistentClient(path=self.chroma_db_path)
        self.embedding_function = self._setup_embedding_function()
        
        # æ·»åŠ ç¼“å­˜
        self.document_cache = {}

    def _setup_docling_converter(self) -> DocumentConverter:
        """ä¸åŸç‰ˆç›¸åŒçš„è®¾ç½®æ–¹å¼"""
        pdf_options = PdfPipelineOptions()
        pdf_options.do_ocr = True
        pdf_options.do_table_structure = True
        
        converter = DocumentConverter(
            format_options={
                InputFormat.PDF: PdfFormatOption(pipeline_options=pdf_options)
            }
        )
        
        return converter

    def _setup_embedding_function(self):
        """ä¼˜åŒ–çš„åµŒå…¥å‡½æ•° - ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹"""
        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEY environment variable is not set.")
        return embedding_functions.OpenAIEmbeddingFunction(
            api_key=self.openai_api_key,
            model_name=self.embedding_model  # è¿™æ˜¯ä¸»è¦ä¼˜åŒ–ç‚¹
        )

    def extract_text_with_docling(self, file_path: str) -> Dict[str, Any]:
        """ä¿®å¤ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜"""
        # æ·»åŠ ç®€å•çš„ç¼“å­˜
        file_hash = self._get_file_hash(file_path)
        if file_hash in self.document_cache:
            print(f"âš¡ Using cached extraction for {Path(file_path).name}")
            return self.document_cache[file_hash]
        
        try:
            start_time = time.time()
            result = self.converter.convert(file_path)
            processing_time = time.time() - start_time

            # ä¿®å¤: åªè·å–markdownå†…å®¹ï¼Œé¿å…ç‰ˆæœ¬å…¼å®¹é—®é¢˜
            markdown_content = result.document.export_to_markdown()
            
            # å°è¯•è·å–JSONï¼Œå¦‚æœå¤±è´¥å°±è·³è¿‡
            json_content = None
            try:
                if hasattr(result.document, 'export_to_json'):
                    json_content = result.document.export_to_json()
                elif hasattr(result.document, 'to_json'):
                    json_content = result.document.to_json()
                else:
                    print("â„¹ï¸ JSON export not available in this Docling version")
            except Exception as json_error:
                print(f"â„¹ï¸ JSON export failed: {json_error}")
                json_content = None

            # å®‰å…¨è·å–title
            title = Path(file_path).name  # é»˜è®¤å€¼
            if hasattr(result.document, 'title') and result.document.title:
                title = result.document.title
            elif hasattr(result, 'title') and result.title:
                title = result.title

            metadata = {
                "source": file_path,
                "title": title,
                "page_count": len(result.document.pages) if hasattr(result.document, 'pages') else 1,
                "format": "markdown",
                "tables_count": self._count_tables(result.document),
                "images_count": self._count_images(result.document),
                "processing_time": processing_time,
                "word_count": len(markdown_content.split()),
                "char_count": len(markdown_content)
            }

            extracted_data = {
                "content": markdown_content,
                "json_content": json_content,  # å¯èƒ½ä¸ºNone
                "metadata": metadata,
                "document_object": result.document
            }
            
            # ç¼“å­˜ç»“æœ
            self.document_cache[file_hash] = extracted_data
            print(f"âœ… Document extracted in {processing_time:.2f}s ({metadata['word_count']} words)")
            return extracted_data

        except Exception as e:
            print(f"âŒ Docling parsing failed for '{file_path}': {e}")
            print(f"ğŸ’¡ Please check if the file is a valid PDF and try again")
            return None

    def _get_file_hash(self, file_path: str) -> str:
        """ç”Ÿæˆæ–‡ä»¶å“ˆå¸Œç”¨äºç¼“å­˜"""
        try:
            with open(file_path, 'rb') as f:
                return hashlib.md5(f.read()).hexdigest()
        except:
            return hashlib.md5(str(file_path).encode()).hexdigest()
    
    def _count_tables(self, document) -> int:
        """å…¼å®¹ç‰ˆæœ¬çš„è¡¨æ ¼è®¡æ•°"""
        try:
            if hasattr(document, 'body') and hasattr(document.body, 'items'):
                return len([item for item in document.body.items if hasattr(item, 'label') and item.label == 'table'])
            else:
                # å°è¯•å…¶ä»–å¯èƒ½çš„å±æ€§å
                return 0
        except Exception as e:
            print(f"â„¹ï¸ Cannot count tables: {e}")
            return 0
    
    def _count_images(self, document) -> int:
        """å…¼å®¹ç‰ˆæœ¬çš„å›¾ç‰‡è®¡æ•°"""
        try:
            if hasattr(document, 'body') and hasattr(document.body, 'items'):
                return len([item for item in document.body.items if hasattr(item, 'label') and item.label == 'picture'])
            else:
                return 0
        except Exception as e:
            print(f"â„¹ï¸ Cannot count images: {e}")
            return 0

    def create_or_get_collection(self, collection_name: str):
        """ä¸åŸç‰ˆç›¸åŒçš„æ¥å£"""
        collection = self.chroma_client.get_or_create_collection(
            name=collection_name,
            embedding_function=self.embedding_function
        )
        print(f"Collection '{collection_name}' is ready.")
        return collection
    
    def chunk_content(self, content: str, chunk_size: int = 800, overlap: int = 150) -> List[str]:
        """ä¼˜åŒ–çš„åˆ†å— - ç¨å¾®å°ä¸€ç‚¹çš„chunkå’Œæ›´å¤šoverlap"""
        chunks = []
        start = 0
        
        while start < len(content):
            end = start + chunk_size
            chunk = content[start:end]
            
            if end < len(content):
                last_period = chunk.rfind('.')
                last_newline = chunk.rfind('\n')
                break_point = max(last_period, last_newline)
                
                if break_point > start + chunk_size // 2:
                    chunk = content[start:break_point + 1]
                    end = break_point + 1
            
            chunks.append(chunk.strip())
            start = end - overlap
        
        return chunks
    
    def embed_document(self, collection_name: str, file_path: str,
                      chunk_size: int = 800, overlap: int = 150) -> bool:
        """ä¸åŸç‰ˆå…¼å®¹ï¼Œä½†ä½¿ç”¨ä¼˜åŒ–å‚æ•°"""
        if not os.path.isfile(file_path):
            print(f"âŒ File not found: {file_path}")
            return False

        collection = self.create_or_get_collection(collection_name)

        existing_docs = collection.get(where={"source": file_path})
        if existing_docs['ids']:
            print(f"â„¹ï¸ Document '{file_path}' already exists. Skipping.")
            return False

        extracted_data = self.extract_text_with_docling(file_path)
        if not extracted_data:
            return False

        content = extracted_data['content']
        metadata = extracted_data['metadata']

        chunks = self.chunk_content(content, chunk_size, overlap)

        documents = chunks
        ids = [f"{Path(file_path).stem}_{i}" for i in range(len(chunks))]
        metadatas = []
        for i, chunk in enumerate(chunks):
            chunk_metadata = metadata.copy()
            chunk_metadata.update({
                "chunk_id": i,
                "chunk_size": len(chunk),
                "total_chunks": len(chunks)
            })
            metadatas.append(chunk_metadata)

        try:
            collection.add(
                documents=documents,
                ids=ids,
                metadatas=metadatas
            )
            print(f"âœ… Successfully embedded {len(chunks)} chunks from '{file_path}'.")
            return True
        except Exception as e:
            print(f"âŒ Failed to add document: {e}")
            return False

# å¤ç”¨åŸç‰ˆçš„äº¤äº’ç•Œé¢ç±»
class InteractiveKnowledgeBase:
    def __init__(self):
        # ä½¿ç”¨ä¼˜åŒ–çš„å¤„ç†å™¨ï¼Œä½†ä¿æŒç›¸åŒæ¥å£
        self.processor = OptimizedDoclingChromaProcessor()
        self.current_collection = None
    
    def run(self):
        """å®Œå…¨ç›¸åŒçš„äº¤äº’ç•Œé¢"""
        print("=== ä¼˜åŒ–ç‰ˆ Docling + ChromaDB Knowledge Base Manager ===")
        print("ğŸš€ æ€§èƒ½ä¼˜åŒ–: å¯ç”¨æ›´å¿«çš„åµŒå…¥æ¨¡å‹å’Œç¼“å­˜")
        
        while True:
            print("\nOptions:")
            print("1. List collections")
            print("2. Create/Select collection")
            print("3. Add document")
            print("4. Query collection")
            print("5. View collection stats")
            print("6. Delete collection")
            print("7. Exit")
            
            choice = input("\nSelect option: ").strip()
            
            if choice == "1":
                self.list_collections()
            elif choice == "2":
                self.create_or_select_collection()
            elif choice == "3":
                self.add_document()
            elif choice == "4":
                self.query_collection()
            elif choice == "5":
                self.view_stats()
            elif choice == "6":
                self.delete_collection()
            elif choice == "7":
                print("Goodbye!")
                break
            else:
                print("Invalid option")
    
    def list_collections(self):
        collections = self.processor.chroma_client.list_collections()
        if collections:
            print("\nğŸ“š Available collections:")
            for i, collection in enumerate(collections, 1):
                try:
                    count = collection.count()
                    print(f"{i}. {collection.name} ({count} documents)")
                except:
                    print(f"{i}. {collection.name}")
        else:
            print("No collections found")
    
    def create_or_select_collection(self):
        name = input("Enter collection name: ").strip()
        if name:
            try:
                self.processor.create_or_get_collection(name)
                self.current_collection = name
                print(f"Selected collection: {name}")
            except Exception as e:
                print(f"Error: {e}")
    
    def add_document(self):
        if not self.current_collection:
            print("Please select a collection first")
            return
        
        file_path = input("Enter file path: ").strip()
        if os.path.isfile(file_path):
            print(f"ğŸš€ Processing with optimizations...")
            success = self.processor.embed_document(
                collection_name=self.current_collection,
                file_path=file_path
            )
            if success:
                print("âœ… Document added successfully with optimizations!")
            else:
                print("âŒ Failed to add document")
        else:
            print("File not found")
    
    def query_collection(self):
        if not self.current_collection:
            print("Please select a collection first")
            return
        
        # è¿™é‡Œæš‚æ—¶ä½¿ç”¨ç®€å•æŸ¥è¯¢ï¼Œå¯ä»¥åç»­ä¼˜åŒ–
        query = input("Enter your query: ").strip()
        if query:
            try:
                collection = self.processor.chroma_client.get_collection(
                    name=self.current_collection,
                    embedding_function=self.processor.embedding_function
                )
                
                results = collection.query(
                    query_texts=[query],
                    n_results=5  # ä¼˜åŒ–: ä»3æ”¹ä¸º5
                )
                
                print(f"\nFound {len(results['documents'][0])} results:")
                for i, (doc, meta) in enumerate(zip(results['documents'][0], results['metadatas'][0]), 1):
                    print(f"\n--- Result {i} ---")
                    print(f"Content: {doc[:300]}...")
                    print(f"Source: {meta.get('source', 'unknown')}")
                    
            except Exception as e:
                print(f"Query failed: {e}")
    
    def view_stats(self):
        if not self.current_collection:
            print("Please select a collection first")
            return
        
        try:
            collection = self.processor.chroma_client.get_collection(
                name=self.current_collection,
                embedding_function=self.processor.embedding_function
            )
            count = collection.count()
            print(f"\nğŸ“Š Collection '{self.current_collection}' Statistics:")
            print(f"Total documents: {count}")
            print(f"Embedding model: {self.processor.embedding_model}")
            print(f"Cache hits: {len(self.processor.document_cache)}")
        except Exception as e:
            print(f"Error getting stats: {e}")
    
    def delete_collection(self):
        self.list_collections()
        name = input("Enter collection name to delete: ").strip()
        if name:
            confirm = input(f"Are you sure you want to delete '{name}'? (y/N): ")
            if confirm.lower() == 'y':
                try:
                    self.processor.chroma_client.delete_collection(name)
                    print(f"Collection '{name}' deleted")
                    if self.current_collection == name:
                        self.current_collection = None
                except Exception as e:
                    print(f"Error: {e}")

# é‡è¦: å¿…é¡»æœ‰è¿™ä¸ªä¸»ç¨‹åºå…¥å£!
if __name__ == "__main__":
    print("ğŸš€ Starting Optimized ChromaDB Manager...")
    manager = InteractiveKnowledgeBase()
    manager.run()